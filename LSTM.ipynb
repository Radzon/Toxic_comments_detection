{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radzon/Toxic_comments_detection/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0v37Cfb4hz8",
        "outputId": "2a8c297b-ea36-4d23-e76a-b39126853825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "p--RLGaKJvLm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "r7_wYMbFw4s6"
      },
      "outputs": [],
      "source": [
        "def pre_data_processing(filepath):\n",
        "  Comments = []\n",
        "  with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "          parts = line.split(' ', 1)\n",
        "          if len(parts) != 2:\n",
        "                continue\n",
        "          label, text = parts\n",
        "          if '__label__NORMAL' == label:\n",
        "            Comments.append((text, 0))\n",
        "          else:\n",
        "            Comments.append((text, 1))\n",
        "  return pd.DataFrame(Comments, columns=['text', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wdJR2oFncz7W"
      },
      "outputs": [],
      "source": [
        "# обработка данных в формат датафрейм\n",
        "df = pre_data_processing('./dataset.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['ladel'].shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "GnTwthLQs4-6"
      },
      "outputs": [],
      "source": [
        "# уравнивание двух классов по меньшему классу \n",
        "df_majority = df[df.label == 0]\n",
        "df_minority = df[df.label == 1]\n",
        "\n",
        "df_majority_downsampled = resample(df_majority,\n",
        "                                   replace=False,\n",
        "                                   n_samples=len(df_minority),\n",
        "                                   random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_majority_downsampled, df_minority])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcPqIpG7cgDP"
      },
      "outputs": [],
      "source": [
        "# настройка токенайзера \n",
        "maxWordsCount = 3000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts(df_balanced['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWuCIzXyhK2e",
        "outputId": "016ebe1a-d53a-4ca4-c35c-829c5e0789fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  43   18  119 ...  216  557  553]\n",
            " [   0    0    0 ...  405 3341 1040]\n",
            " [   0    0    0 ...  501  591   23]\n",
            " ...\n",
            " [   0    0    0 ... 1891  124  911]\n",
            " [   0    0    0 ...  191 2081  286]\n",
            " [   0    0    0 ... 2662   16    3]]\n"
          ]
        }
      ],
      "source": [
        "# превращение комментариев в вектор с 0 место пропусков (если предложение маленькое)\n",
        "max_text_len = 16\n",
        "data = tokenizer.texts_to_sequences(df_balanced['text'])\n",
        "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
        "print(data_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4_2FYhFE0V0F"
      },
      "outputs": [],
      "source": [
        "# переименование текста и значений\n",
        "X = data_pad\n",
        "Y = np.array(df_balanced['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "suKcqXaKzNkM"
      },
      "outputs": [],
      "source": [
        "# случайное перемешивание примеров\n",
        "indeces = np.random.choice(X.shape[0], size=X.shape[0], replace=False)\n",
        "X = X[indeces]\n",
        "Y = Y[indeces]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rpaJTrlMlHTf"
      },
      "outputs": [],
      "source": [
        "# разбивка на трейн и тест\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dby0fzPghqtW",
        "outputId": "20ab9f7a-4579-4b99-d959-a7e3ef63beba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 16, 128)           512000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 16, 256)           263168    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 128)               164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 939649 (3.58 MB)\n",
            "Trainable params: 939649 (3.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# создание модели\n",
        "model = Sequential()\n",
        "model.add(Embedding(maxWordsCount, 128, input_length=max_text_len))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2hM_qGep4Zb9"
      },
      "outputs": [],
      "source": [
        "# сохранение лучших весов по метрике val_accuracy\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
        "\n",
        "# предварительная остановка обучения если точность на валидации не изменяется\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RAkF71OhwQm",
        "outputId": "a12fc64c-633a-477b-8670-b86600c378fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8285\n",
            "Epoch 1: val_accuracy improved from -inf to 0.89344, saving model to best_model.h5\n",
            "2370/2370 [==============================] - 266s 109ms/step - loss: 0.3564 - accuracy: 0.8285 - val_loss: 0.2524 - val_accuracy: 0.8934\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.8982\n",
            "Epoch 2: val_accuracy improved from 0.89344 to 0.89516, saving model to best_model.h5\n",
            "2370/2370 [==============================] - 263s 111ms/step - loss: 0.2435 - accuracy: 0.8982 - val_loss: 0.2472 - val_accuracy: 0.8952\n",
            "Epoch 3/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9027\n",
            "Epoch 3: val_accuracy improved from 0.89516 to 0.89643, saving model to best_model.h5\n",
            "2370/2370 [==============================] - 265s 112ms/step - loss: 0.2300 - accuracy: 0.9027 - val_loss: 0.2483 - val_accuracy: 0.8964\n",
            "Epoch 4/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9071\n",
            "Epoch 4: val_accuracy improved from 0.89643 to 0.89650, saving model to best_model.h5\n",
            "2370/2370 [==============================] - 266s 112ms/step - loss: 0.2217 - accuracy: 0.9071 - val_loss: 0.2452 - val_accuracy: 0.8965\n",
            "Epoch 5/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9092\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "2370/2370 [==============================] - 267s 113ms/step - loss: 0.2141 - accuracy: 0.9092 - val_loss: 0.2485 - val_accuracy: 0.8960\n",
            "Epoch 6/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9121\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "2370/2370 [==============================] - 265s 112ms/step - loss: 0.2075 - accuracy: 0.9121 - val_loss: 0.2530 - val_accuracy: 0.8934\n",
            "Epoch 7/20\n",
            "2370/2370 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9138\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "2370/2370 [==============================] - 256s 108ms/step - loss: 0.2011 - accuracy: 0.9138 - val_loss: 0.2584 - val_accuracy: 0.8941\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ],
      "source": [
        "# обучение\n",
        "history = model.fit(X_train, Y_train, batch_size=32, epochs=20, validation_data=(X_test, Y_test), callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7xbu3H07o5UJ"
      },
      "outputs": [],
      "source": [
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "def sequence_to_text(list_of_indices):\n",
        "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
        "    return(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTFMazVFo64Y",
        "outputId": "9be23867-605f-46a7-e8aa-f00bde515c35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['закрой', 'свой', 'рот']\n"
          ]
        }
      ],
      "source": [
        "# в переменную t можно  записать свое предложение для проверки\n",
        "t = \"закрой свой рот\".lower()\n",
        "data = tokenizer.texts_to_sequences([t])\n",
        "t = pad_sequences(data, maxlen=max_text_len)\n",
        "print( sequence_to_text(data[0]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWqgXxLAo7_Y",
        "outputId": "1fe3b410-0ded-43c1-a3a0-5050953941f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[[0.99381876]]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# проверка предложения\n",
        "res = model.predict(t)\n",
        "print(res, np.argmax(res), sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDKw3-rGsV9y",
        "outputId": "129a4461-f42a-47f8-cd4e-d2abf497320a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "419/419 [==============================] - 13s 30ms/step\n",
            "Precision: 0.9331928003891682\n",
            "Recall: 0.8553804994054697\n"
          ]
        }
      ],
      "source": [
        "# оценка всей моодели на тесте\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "Y_pred_classes = (Y_pred > 0.5).astype(int).flatten()\n",
        "\n",
        "precision = precision_score(Y_test, Y_pred_classes)\n",
        "recall = recall_score(Y_test, Y_pred_classes)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMZvi8VLbh4Ja+9GyYjIYZD",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
